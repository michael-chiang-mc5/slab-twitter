Instructions on server: 104.131.145.75
  (1) activate virtual environment
  (2) check for existing python thread
        ps auxww | grep collectTweets_LA.py
      If it exists, kill
  (3) Run: sh collectTweets_LA.sh
        stdout will be directed to collectTweets_LA.out
        results will be written to twitter_data/la_stream.json

Instructions on workstation:
  (1) Edit parameters in parameters.py
  (2) Run collectTweets_LA.py to record a bunch of tweets (THIS SHOULD BE DONE ON SERVER). 300-1000 tweets per hour depending on time of day
  (2) Run createMapTemplate.py. This creates a template where tweet locations can be plotted
  (3) Run plotLocationsOnMapTemplate.py. This creates a figure where tweet locations are overlaid on a map
  (4) Run wordCloud.py
  (5) Run wordCloud_comparison.py


Todo:
collectTweets -> streamTweets_boundingBox
collectTweets -> streamTweets_query

wordcloud with bounding box for cities

Fisher exact test, hypergeometric
chi2 + bonferroni
https://www.researchgate.net/post/comparing_frequency_counts_between_two_groups_of_different_sample_size_Chi-square

Other notes:
****

main.py, main2.py, main3.py are example python files

1_collectTweets.py uses twitter api to store tweets
ps auxww | grep collectTweets_LA.py
****

Aim 1:
Run the following terminal command:


****

need global packages for python:
virtualenv --system-site-packages -p python3.4 venv

install basemap, geos from source not pip
